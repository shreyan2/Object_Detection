{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Object Detection using YOLO.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvMnDpBT6WRk",
        "outputId": "feb6d2f1-3342-4e8c-ef40-ee25debc3d56"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Object Recog/Yolo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWKtgncr8juY",
        "outputId": "b7bbccc8-dcb6-43f3-820b-97c1094b98f7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Object Recog/Yolo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_q14YL8W5jj3",
        "outputId": "3243bcd6-f239-41ab-fe03-65be7738472b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Object Recog/Yolo'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkOw5kGq8nGf",
        "outputId": "1d847338-adea-46ce-da82-b80f5ca80297"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-04 17:15:56--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘yolov3.weights’\n",
            "\n",
            "yolov3.weights      100%[===================>] 236.52M  36.8MB/s    in 6.8s    \n",
            "\n",
            "2022-03-04 17:16:03 (35.0 MB/s) - ‘yolov3.weights’ saved [248007048/248007048]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import subprocess\n",
        "import time\n",
        "import os\n",
        "\n",
        "def show_image(img):\n",
        "    cv2.imshow(\"Image\", img)\n",
        "    cv2.waitKey(0)\n",
        "\n",
        "def draw_labels_and_boxes(img, boxes, confidences, classids, idxs, colors, labels):\n",
        "    # If there are any detections\n",
        "    if len(idxs) > 0:\n",
        "        for i in idxs.flatten():\n",
        "            # Get the bounding box coordinates\n",
        "            x, y = boxes[i][0], boxes[i][1]\n",
        "            w, h = boxes[i][2], boxes[i][3]\n",
        "            \n",
        "            # Get the unique color for this class\n",
        "            color = [int(c) for c in colors[classids[i]]]\n",
        "\n",
        "            # Draw the bounding box rectangle and label on the image\n",
        "            cv2.rectangle(img, (x, y), (x+w, y+h), color, 2)\n",
        "            text = \"{}: {:4f}\".format(labels[classids[i]], confidences[i])\n",
        "            cv2.putText(img, text, (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def generate_boxes_confidences_classids(outs, height, width, tconf):\n",
        "    boxes = []\n",
        "    confidences = []\n",
        "    classids = []\n",
        "\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            #print (detection)\n",
        "            #a = input('GO!')\n",
        "            \n",
        "            # Get the scores, classid, and the confidence of the prediction\n",
        "            scores = detection[5:]\n",
        "            classid = np.argmax(scores)\n",
        "            confidence = scores[classid]\n",
        "            \n",
        "            # Consider only the predictions that are above a certain confidence level\n",
        "            if confidence > tconf:\n",
        "                # TODO Check detection\n",
        "                box = detection[0:4] * np.array([width, height, width, height])\n",
        "                centerX, centerY, bwidth, bheight = box.astype('int')\n",
        "\n",
        "                # Using the center x, y coordinates to derive the top\n",
        "                # and the left corner of the bounding box\n",
        "                x = int(centerX - (bwidth / 2))\n",
        "                y = int(centerY - (bheight / 2))\n",
        "\n",
        "                # Append to list\n",
        "                boxes.append([x, y, int(bwidth), int(bheight)])\n",
        "                confidences.append(float(confidence))\n",
        "                classids.append(classid)\n",
        "\n",
        "    return boxes, confidences, classids\n",
        "\n",
        "confidence=0.5 #default is set to 0.5\n",
        "threshold=0.3 #The threshold to use when applying the Non-Max Suppresion\n",
        "\n",
        "def infer_image(net, layer_names, height, width, img, colors, labels, \n",
        "            boxes=None, confidences=None, classids=None, idxs=None, infer=True):\n",
        "    \n",
        "    if infer:\n",
        "        # Contructing a blob from the input image\n",
        "        blob = cv2.dnn.blobFromImage(img, 1 / 255.0, (416, 416), \n",
        "                        swapRB=True, crop=False)\n",
        "\n",
        "        # Perform a forward pass of the YOLO object detector\n",
        "        net.setInput(blob)\n",
        "\n",
        "        # Getting the outputs from the output layers\n",
        "        start = time.time()\n",
        "        outs = net.forward(layer_names)\n",
        "        end = time.time()\n",
        "\n",
        "        \n",
        "        #print (\"YOLOv3 took {:6f} seconds\".format(end - start)) #Uncomment this line to print the time the model takes \n",
        "\n",
        "\n",
        "        \n",
        "        # Generate the boxes, confidences, and classIDs\n",
        "        boxes, confidences, classids = generate_boxes_confidences_classids(outs, height, width,confidence)\n",
        "        \n",
        "        # Apply Non-Maxima Suppression to suppress overlapping bounding boxes\n",
        "        idxs = cv2.dnn.NMSBoxes(boxes, confidences,confidence,threshold)\n",
        "\n",
        "    if boxes is None or confidences is None or idxs is None or classids is None:\n",
        "        raise 'Required variables for drawing boxes on images are set to None.'\n",
        "        \n",
        "    # Draw labels and boxes on the image\n",
        "    img = draw_labels_and_boxes(img, boxes, confidences, classids, idxs, colors, labels)\n",
        "\n",
        "    return img, boxes, confidences, classids, idxs\n"
      ],
      "metadata": {
        "id": "aVIojNA58pD2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = open('/content/drive/MyDrive/Object Recog/Yolo/coco-labels').read().strip().split('\\n')\n",
        "colors = np.random.randint(0, 255, size=(len(labels), 3), dtype='uint8')\n",
        "video_path='/content/drive/MyDrive/Object Recog/Road traffic.mp4' #The path to the video which you wish to use for detection\n",
        "video_output_path='/content/drive/MyDrive/Object Recog/output.avi' \n",
        "# Load the weights and configutation to form the pretrained YOLOv3 model\n",
        "net = cv2.dnn.readNetFromDarknet('/content/drive/MyDrive/Object Recog/Yolo/yolov3.cfg', '/content/drive/MyDrive/Object Recog/Yolo/yolov3.weights')\n",
        "\n",
        "\n",
        "layer_names = net.getLayerNames()\n",
        "layer_names = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "\t\n",
        "vid = cv2.VideoCapture(video_path)\n",
        "height, width = None, None\n",
        "writer = None\n",
        "while True:\n",
        "\t\tgrabbed, frame = vid.read()\n",
        "\t  \n",
        "\t\tif not grabbed:\n",
        "\t\t\tbreak\n",
        "\n",
        "\t\tif width is None or height is None:\n",
        "\t\t\theight, width = frame.shape[:2]\n",
        "\t\t\n",
        "\t\tframe, _, _, _, _ = infer_image(net, layer_names, height, width, frame, colors, labels)\n",
        "\t  \n",
        "\t\tif writer is None:\n",
        "\t\t\tfourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "\t\t\twriter = cv2.VideoWriter(video_output_path, fourcc, 30, \n",
        "\t\t\t\t\t\t            (frame.shape[1], frame.shape[0]), True)\n",
        "\n",
        "\t\twriter.write(frame)\n",
        "\n",
        "     \n",
        "\n",
        "\n",
        "writer.release()\n",
        "vid.release()\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "\n"
      ],
      "metadata": {
        "id": "1rtm7b359wUA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6Kfu8n4C9M3S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}